{
  "id": "ai.chat",
  "name": "Chat Model",
  "version": 2,
  "nodeVersion": "1.0.0",
  "author": "Fuse Official",
  "category": "AI",
  "service": "core",
  "connectionType": "flow",
  "description": "Configure a Chat Model (LLM) for use in agents.",
  "tags": [
    "ai",
    "llm",
    "chat",
    "model",
    "config"
  ],
  "icon": "cpu",
  "runtime": {
    "type": "internal",
    "language": "python",
    "minPythonVersion": "3.9"
  },
  "inputs": [
    {
      "name": "credential",
      "type": "credential",
      "label": "AI Provider",
      "credential_type": "ai_provider,google_ai,github_copilot",
      "required": true,
      "description": "Select AI Provider (OpenAI, Google, Anthropic, etc.)"
    },
    {
      "name": "model",
      "type": "select",
      "label": "Model",
      "required": true,
      "dynamic_options": "get_models",
      "dynamic_dependencies": [
        "credential"
      ],
      "description": "Select the specific model to use"
    },
    {
      "name": "temperature",
      "type": "number",
      "label": "Temperature",
      "default": 0.7,
      "description": "Randomness (0.0 - 1.0)"
    }
  ],
  "outputs": [
    {
      "name": "model",
      "type": "ai_model",
      "label": "Model Config",
      "description": "Model configuration object"
    }
  ],
  "credentials": [
    "multi"
  ],
  "pricing": {
    "model": "free",
    "price": 0
  },
  "visibility": "public",
  "license": "MIT"
}